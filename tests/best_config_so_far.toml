classes = []
optimizer = "nadam"
lr = 0.0003
lr_scheduler = "exponential"
dropout = 0.1
hidden_layers = [512, 128]
normalization = "layer"
batch_size = 3
num_epochs = 100
patience = 10
base_model = "prajjwal1/bert-mini"
base_layers_to_unfreeze = 0
entity_loss_scaling_factor = 1
relation_label_smoothing = 0.1
model_class = "ETEBrendaModel"
