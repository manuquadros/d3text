optimizer = "nadam"
lr = 0.001
lr_scheduler = "exponential"
dropout = 0.2
hidden_layers = [128]
normalization = "layer"
batch_size = 3
num_epochs = 100
patience = 10
base_model = "michiyasunaga/BioLinkBERT-base"
base_layers_to_unfreeze = 0
entity_loss_scaling_factor = 1
relation_label_smoothing = 0
model_class = "ETEBrendaModel"
common_hidden_block = true
ramp_epochs = 4
separate_predicate_layer = true
